{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a989f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the independent and target variable datasets\n",
    "\n",
    "stock = 'AAPL'\n",
    "window_size = 20\n",
    "pred_horizon = 10\n",
    "\n",
    "X = pd.read_parquet(stock + '_X_' + str(window_size) + 'D.gzip')\n",
    "y = pd.read_parquet(stock + '_y_' + str(pred_horizon) + 'D.gzip')\n",
    "y = y.cumsum(axis=1)\n",
    "y = y.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c47d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation and test datasets\n",
    "\n",
    "num_features = 20\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "q_80 = int(len(X) * .8)\n",
    "q_90 = int(len(X) * .9)\n",
    "\n",
    "X_train, y_train = X[:q_80].to_numpy(), y[:q_80].to_numpy()\n",
    "X_val, y_val = X[q_80:q_90].to_numpy(), y[q_80:q_90].to_numpy()\n",
    "X_test, y_test = X[q_90:].to_numpy(), y[q_90:].to_numpy()\n",
    "\n",
    "X_train = X_train.reshape((-1, window_size, num_features))\n",
    "X_val = X_val.reshape((-1, window_size, num_features))\n",
    "X_test = X_test.reshape((-1, window_size, num_features))\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b599a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping callback to be used in all neural networks\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        \n",
    "    patience=5,                # wait 5 epochs for improvement\n",
    "    restore_best_weights=True  # roll back to best weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an RNN model to the dataset\n",
    "\n",
    "model_RNN = Sequential([\n",
    "    SimpleRNN(128, \n",
    "         input_shape=(window_size, num_features), \n",
    "         dropout=0.2,               # dropout on input (per time step)\n",
    "         recurrent_dropout=0.2),    # dropout on hidden state (across time)\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(16, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(8, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_RNN.compile(loss='mean_absolute_error', \n",
    "              optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "model_RNN.fit(X_train, y_train_scaled, validation_data=(X_val, y_val_scaled), epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an LSTM model to the dataset\n",
    "\n",
    "model_LSTM = Sequential([\n",
    "    LSTM(128, \n",
    "         input_shape=(window_size, num_features), \n",
    "         dropout=0.2,               # dropout on input (per time step)\n",
    "         recurrent_dropout=0.2),    # dropout on hidden state (across time)\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(16, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(8, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_LSTM.compile(loss='mean_absolute_error', \n",
    "              optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "model_LSTM.fit(X_train, y_train_scaled, validation_data=(X_val, y_val_scaled), epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1478222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a GRU model to the dataset\n",
    "\n",
    "model_GRU = Sequential([\n",
    "    GRU(128, \n",
    "         input_shape=(window_size, num_features), \n",
    "         dropout=0.2,               # dropout on input (per time step)\n",
    "         recurrent_dropout=0.2),    # dropout on hidden state (across time)\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(16, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(8, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_GRU.compile(loss='mean_absolute_error', \n",
    "              optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "model_GRU.fit(X_train, y_train_scaled, validation_data=(X_val, y_val_scaled), epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First calculate the baseline absolute errors \n",
    "train_baseline_errors = np.abs(y_train)\n",
    "val_baseline_errors = np.abs(y_val)\n",
    "test_baseline_errors = np.abs(y_test)\n",
    "\n",
    "# Calculate the mean absolute baseline errors for each dataset\n",
    "avg_train_baseline_errors = train_baseline_errors.mean(axis=0)[0]\n",
    "avg_val_baseline_errors = val_baseline_errors.mean(axis=0)[0]\n",
    "avg_test_baseline_errors = test_baseline_errors.mean(axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the return (close) using the trained RNN model and calculate errors\n",
    "\n",
    "# Train dataset\n",
    "y_train_pred_scaled_RNN = model_RNN.predict(X_train)\n",
    "y_train_pred_RNN = scaler_y.inverse_transform(y_train_pred_scaled_RNN)\n",
    "train_errors_RNN = np.abs(y_train_pred_RNN - y_train)\n",
    "\n",
    "# Validation dataset\n",
    "y_val_pred_scaled_RNN = model_RNN.predict(X_val)\n",
    "y_val_pred_RNN = scaler_y.inverse_transform(y_val_pred_scaled_RNN)\n",
    "val_errors_RNN = np.abs(y_val_pred_RNN - y_val)\n",
    "\n",
    "# Test dataset\n",
    "y_test_pred_scaled_RNN = model_RNN.predict(X_test)\n",
    "y_test_pred_RNN = scaler_y.inverse_transform(y_test_pred_scaled_RNN)\n",
    "test_errors_RNN = np.abs(y_test_pred_RNN - y_test)\n",
    "\n",
    "# Calculate the mean absolute errors for each dataset\n",
    "avg_train_errors_RNN = train_errors_RNN.mean(axis=0)[0]\n",
    "avg_val_errors_RNN = val_errors_RNN.mean(axis=0)[0]\n",
    "avg_test_errors_RNN = test_errors_RNN.mean(axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the return (close) using the trained LSTM model and calculate errors\n",
    "\n",
    "# Train dataset\n",
    "y_train_pred_scaled_LSTM = model_LSTM.predict(X_train)\n",
    "y_train_pred_LSTM = scaler_y.inverse_transform(y_train_pred_scaled_LSTM)\n",
    "train_errors_LSTM = np.abs(y_train_pred_LSTM - y_train)\n",
    "\n",
    "# Validation dataset\n",
    "y_val_pred_scaled_LSTM = model_LSTM.predict(X_val)\n",
    "y_val_pred_LSTM = scaler_y.inverse_transform(y_val_pred_scaled_LSTM)\n",
    "val_errors_LSTM = np.abs(y_val_pred_LSTM - y_val)\n",
    "\n",
    "# Test dataset\n",
    "y_test_pred_scaled_LSTM = model_LSTM.predict(X_test)\n",
    "y_test_pred_LSTM = scaler_y.inverse_transform(y_test_pred_scaled_LSTM)\n",
    "test_errors_LSTM = np.abs(y_test_pred_LSTM - y_test)\n",
    "\n",
    "# Calculate the mean absolute errors for each dataset\n",
    "avg_train_errors_LSTM = train_errors_LSTM.mean(axis=0)[0]\n",
    "avg_val_errors_LSTM = val_errors_LSTM.mean(axis=0)[0]\n",
    "avg_test_errors_LSTM = test_errors_LSTM.mean(axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the return (close) using the trained GRU model and calculate errors\n",
    "\n",
    "# Train dataset\n",
    "y_train_pred_scaled_GRU = model_GRU.predict(X_train)\n",
    "y_train_pred_GRU = scaler_y.inverse_transform(y_train_pred_scaled_GRU)\n",
    "train_errors_GRU = np.abs(y_train_pred_GRU - y_train)\n",
    "\n",
    "# Validation dataset\n",
    "y_val_pred_scaled_GRU = model_GRU.predict(X_val)\n",
    "y_val_pred_GRU = scaler_y.inverse_transform(y_val_pred_scaled_GRU)\n",
    "val_errors_GRU = np.abs(y_val_pred_GRU - y_val)\n",
    "\n",
    "# Test dataset\n",
    "y_test_pred_scaled_GRU = model_GRU.predict(X_test)\n",
    "y_test_pred_GRU = scaler_y.inverse_transform(y_test_pred_scaled_GRU)\n",
    "test_errors_GRU = np.abs(y_test_pred_GRU - y_test)\n",
    "\n",
    "# Calculate the mean absolute errors for each dataset\n",
    "avg_train_errors_GRU = train_errors_GRU.mean(axis=0)[0]\n",
    "avg_val_errors_GRU = val_errors_GRU.mean(axis=0)[0]\n",
    "avg_test_errors_GRU = test_errors_GRU.mean(axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_errors = {\n",
    "    'Baseline': [avg_train_baseline_errors, avg_val_baseline_errors, avg_test_baseline_errors],\n",
    "    'RNN': [avg_train_errors_RNN, avg_val_errors_RNN, avg_test_errors_RNN],\n",
    "    'LSTM': [avg_train_errors_LSTM, avg_val_errors_LSTM, avg_test_errors_LSTM],\n",
    "    'GRU': [avg_train_errors_GRU, avg_val_errors_GRU, avg_test_errors_GRU]\n",
    "    }\n",
    "\n",
    "df_errors = pd.DataFrame(data=data_errors, index=['Train', 'Validation', 'Test']) * 100\n",
    "df_errors = df_errors.apply(lambda x: round(x, 4))\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061211b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
